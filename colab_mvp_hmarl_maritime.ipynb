{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "135b4fa4",
      "metadata": {},
      "source": [
        "# Hierarchical Multi-Agent Reinforcement Learning for Congestion-Aware Vessel Scheduling\n",
        "\n",
        "**Supervised by Prof. Aboussalah**  \\n**Spring 2026 Independent Study**\n",
        "\n",
        "This Colab notebook is an MVP (minimum viable prototype) that sketches a working pipeline for hierarchical MARL with congestion forecasting and port coordination. The goal is to be **descriptive**, **traceable**, and **executable** with simplified components so we can iterate quickly before scaling to a full simulator and MAPPO training."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "518ec614",
      "metadata": {},
      "source": [
        "## Table of contents\n",
        "1. Project framing, objectives, and research questions\n",
        "2. Architecture and data flow\n",
        "3. Configuration\n",
        "4. Simulator (MVP environment)\n",
        "   - 4.1 State definitions and initialization\n",
        "   - 4.2 Environment dynamics (vessel movement, port operations, emissions)\n",
        "   - 4.3 Gymnasium environment skeleton\n",
        "5. Forecasting module (mock)\n",
        "6. Agent decision stubs (hierarchical control)\n",
        "   - 6.1 Centralized critic stub (CTDE)\n",
        "7. Reward functions\n",
        "8. Metrics and evaluation hooks\n",
        "   - 8.1 Forecasting, agent, coordination, and economic metrics\n",
        "9. Experiment protocol and baselines\n",
        "   - 9.1 Ablation runner framework\n",
        "10. MVP execution and visualization\n",
        "    - 10.1 Rollout with full pipeline\n",
        "    - 10.2 Baseline comparison (forecast vs reactive vs independent)\n",
        "11. MVP-to-Research checklist\n",
        "12. Next steps for the full project\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7313c58",
      "metadata": {},
      "source": [
        "## 1. Project framing, objectives, and research questions\n",
        "We model a maritime network with **heterogeneous agents**:\n",
        "- **Fleet coordinator** (strategic decisions, 12–24h cadence)\n",
        "- **Vessel agents** (operational speed/arrival control, 1–4h cadence)\n",
        "- **Port agents** (dock allocation and service scheduling, 2–6h cadence)\n",
        "\n",
        "**MVP objectives**:\n",
        "- Validate the **information flow** between forecasting, coordinator, vessel, and port layers.\n",
        "- Provide a **minimal environment** with vessel movement, port queuing, and emission tracking.\n",
        "- Establish **reward functions** and **metric hooks** that map directly to the full study.\n",
        "- Demonstrate baseline comparisons (independent → reactive → forecast-informed → oracle).\n",
        "\n",
        "We simulate a small system (1 coordinator, 8 vessels, 5 ports) and use a toy environment to demonstrate the **data flow** and **learning loops**.\n",
        "\n",
        "### Research questions traced in this MVP\n",
        "| RQ | Question | Where tested |\n",
        "|----|----------|--------------|\n",
        "| **RQ1** | How can heterogeneous agents coordinate using shared congestion forecasts to minimize system-wide costs? | §6 policies, §10 rollout |\n",
        "| **RQ2** | Does proactive coordination with forecasts improve over (a) independent and (b) reactive policies? | §10.2 baseline comparison |\n",
        "| **RQ3** | How should forecasts be distributed among agents, and which horizons help most? | §9.1 ablation runner |\n",
        "| **RQ4** | How do coordination improvements affect economic outcomes (price, reliability)? | §8.1 economic metrics |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bc43900",
      "metadata": {},
      "source": [
        "## 2. Architecture and data flow\n",
        "```\n",
        "Fleet Coordinator  → (Strategic Directives) →  Vessel Agents  → (Arrival Requests) →  Port Agents\n",
        "Port Agents        → (Dock Availability)   →  Vessel Agents\n",
        "```\n",
        "**Forecasting usage**:\n",
        "- Medium-term forecasts (3–7 days) inform the **fleet coordinator**.\n",
        "- Short-term forecasts (6–24 hours) inform **vessels and ports**.\n",
        "\n",
        "This MVP will keep policies simple but will expose the exact data each agent sees."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f389c0c8",
      "metadata": {},
      "source": [
        "### 2.1 MDP summary (MVP view)\n",
        "We keep the MDP definition lightweight here and focus on the observation/action channels that will later map to Gymnasium spaces."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4568add",
      "metadata": {},
      "source": [
        "### 2.2 Observation and action schema (MVP interface)\n",
        "To keep the prototype coherent across modules, we define a consistent interface for each agent. This will later map directly to Gymnasium spaces.\n",
        "\n",
        "**Fleet coordinator**\n",
        "- **Obs**: [port congestion forecast (P × Hm), vessel summaries (V × k), cumulative emissions]\n",
        "- **Act**: [destination port (categorical P), departure window (hours), emission budget] \n",
        "\n",
        "**Vessel agent**\n",
        "- **Obs**: [current port, speed, fuel, short-term forecast for destination (Hs), coordinator directive, dock availability] \n",
        "- **Act**: [speed setting (continuous), requested arrival time] \n",
        "\n",
        "**Port agent**\n",
        "- **Obs**: [queue length, dock occupancy, expected arrivals, vessel requests] \n",
        "- **Act**: [dock assignment, service priority order] \n",
        "\n",
        "This schema is intentionally compact so we can test wiring before scaling state complexity.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1fc9456",
      "metadata": {},
      "source": [
        "### 2.3 Centralized critic view (CTDE placeholder)\n",
        "During training, a centralized critic can consume the concatenated global state: [all agent observations + joint actions + global congestion stats].\n",
        "This notebook keeps it as a placeholder to ensure MAPPO compatibility later.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b68d905",
      "metadata": {},
      "outputs": [],
      "source": [
        "mdp_summary = pd.DataFrame(\n",
        "    [\n",
        "        {\n",
        "            \"agent\": \"Fleet Coordinator\",\n",
        "            \"observations\": \"Medium-term forecasts, vessel states, emissions\",\n",
        "            \"actions\": \"Destination port, departure window, emission budget\",\n",
        "            \"reward\": \"- (voyage cost + emission penalty)\",\n",
        "        },\n",
        "        {\n",
        "            \"agent\": \"Vessel\",\n",
        "            \"observations\": \"Short-term forecasts, position/speed, directives\",\n",
        "            \"actions\": \"Speed adjustment, arrival request\",\n",
        "            \"reward\": \"- (fuel + delay + emissions)\",\n",
        "        },\n",
        "        {\n",
        "            \"agent\": \"Port\",\n",
        "            \"observations\": \"Queue, dock occupancy, arrival requests\",\n",
        "            \"actions\": \"Dock allocation, service rate\",\n",
        "            \"reward\": \"- (queue wait + dock idle)\",\n",
        "        },\n",
        "    ]\n",
        ")\n",
        "mdp_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01b77bbb",
      "metadata": {},
      "source": [
        "## 3. Configuration\n",
        "We keep dependencies minimal for the MVP. In a full implementation, this section will include MARL frameworks (e.g., RLlib, MARLlib) and forecasting libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2db87385",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from copy import deepcopy\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "SEED = 42\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25623c6c",
      "metadata": {},
      "source": [
        "### 3.1 Core experiment parameters\n",
        "We centralize key parameters so the team can adjust horizons, weights, and counts in one place."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6ad1c66",
      "metadata": {},
      "outputs": [],
      "source": [
        "CONFIG = {\n",
        "    # --- Fleet topology ---\n",
        "    \"num_ports\": 5,\n",
        "    \"num_vessels\": 8,\n",
        "    \"docks_per_port\": 3,\n",
        "\n",
        "    # --- Forecast horizons ---\n",
        "    \"medium_horizon_days\": 5,\n",
        "    \"short_horizon_hours\": 12,\n",
        "\n",
        "    # --- Reward weights (α, β, γ in the proposal) ---\n",
        "    \"fuel_weight\": 1.0,       # α\n",
        "    \"delay_weight\": 1.5,      # β\n",
        "    \"emission_weight\": 0.7,   # γ\n",
        "    \"emission_lambda\": 2.0,   # λ  (coordinator emission penalty)\n",
        "    \"dock_idle_weight\": 0.5,  # port idle-dock penalty\n",
        "\n",
        "    # --- Physics (simplified) ---\n",
        "    \"fuel_rate_coeff\": 0.002,        # fuel consumption: k * speed^3 (tons/hour)\n",
        "    \"emission_factor\": 3.114,        # tons CO2 per ton of fuel (IMO default)\n",
        "    \"speed_min\": 8.0,                # knots\n",
        "    \"speed_max\": 18.0,               # knots\n",
        "    \"nominal_speed\": 12.0,           # knots\n",
        "\n",
        "    # --- Economic parameters (RQ4) ---\n",
        "    \"cargo_value_per_vessel\": 1_000_000,  # USD (notional)\n",
        "    \"fuel_price_per_ton\": 600,            # USD\n",
        "    \"delay_penalty_per_hour\": 5_000,      # USD\n",
        "    \"carbon_price_per_ton\": 90,           # USD (EU ETS ballpark)\n",
        "\n",
        "    # --- Simulation ---\n",
        "    \"rollout_steps\": 20,\n",
        "    \"seed\": SEED,\n",
        "}\n",
        "\n",
        "# Distance matrix (nautical miles) between 5 ports — symmetric\n",
        "# Ports: 0=Singapore, 1=Rotterdam, 2=Shanghai, 3=Dubai, 4=Los Angeles (notional)\n",
        "DISTANCE_NM = np.array([\n",
        "    [   0,  8400,  2200,  3400, 7800],\n",
        "    [8400,     0,  9800,  6100, 5400],\n",
        "    [2200,  9800,     0,  5500, 5900],\n",
        "    [3400,  6100,  5500,     0, 8200],\n",
        "    [7800,  5400,  5900,  8200,    0],\n",
        "], dtype=float)\n",
        "\n",
        "CONFIG\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5bc0d3c",
      "metadata": {},
      "source": [
        "## 4. Simulator (MVP environment)\n",
        "We implement a **discrete-event toy simulator** that captures the key physical signals: vessel transit between ports, fuel consumption, CO₂ emissions, queue lengths, and dock occupancy. This is intentionally small and interpretable so we can debug coordination and forecast usage early.\n",
        "\n",
        "### 4.1 State definitions and initialization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "734e65f0",
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class PortState:\n",
        "    \"\"\"State of a single port.\"\"\"\n",
        "    port_id: int\n",
        "    queue: int                          # vessels waiting for a dock\n",
        "    docks: int                          # total dock capacity\n",
        "    occupied: int                       # docks currently in use\n",
        "    cumulative_wait_hours: float = 0.0  # total waiting time accumulated\n",
        "    vessels_served: int = 0             # count of vessels served\n",
        "\n",
        "@dataclass\n",
        "class VesselState:\n",
        "    \"\"\"State of a single vessel.\"\"\"\n",
        "    vessel_id: int\n",
        "    location: int              # current port index (-1 = at sea)\n",
        "    destination: int           # target port index\n",
        "    position_nm: float = 0.0   # nautical miles traveled on current leg\n",
        "    speed: float = 12.0        # current speed in knots\n",
        "    fuel: float = 100.0        # remaining fuel (tons)\n",
        "    emissions: float = 0.0     # cumulative CO2 (tons)\n",
        "    delay_hours: float = 0.0   # accumulated delay vs scheduled arrival\n",
        "    at_sea: bool = False       # True when transiting between ports\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Initialization helpers\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "def make_rng(seed: int = SEED) -> np.random.Generator:\n",
        "    \"\"\"Create a fresh RNG — avoids shared-state bugs across experiments.\"\"\"\n",
        "    return np.random.default_rng(seed)\n",
        "\n",
        "def initialize_ports(num_ports: int, docks_per_port: int = 3,\n",
        "                     rng: np.random.Generator = None) -> List[PortState]:\n",
        "    rng = rng or make_rng()\n",
        "    return [\n",
        "        PortState(\n",
        "            port_id=i,\n",
        "            queue=int(rng.integers(0, 5)),\n",
        "            docks=docks_per_port,\n",
        "            occupied=int(rng.integers(0, docks_per_port)),\n",
        "        )\n",
        "        for i in range(num_ports)\n",
        "    ]\n",
        "\n",
        "def initialize_vessels(num_vessels: int, num_ports: int,\n",
        "                       rng: np.random.Generator = None) -> List[VesselState]:\n",
        "    rng = rng or make_rng()\n",
        "    return [\n",
        "        VesselState(\n",
        "            vessel_id=i,\n",
        "            location=int(rng.integers(0, num_ports)),\n",
        "            destination=int(rng.integers(0, num_ports)),\n",
        "            speed=CONFIG[\"nominal_speed\"],\n",
        "            fuel=100.0,\n",
        "        )\n",
        "        for i in range(num_vessels)\n",
        "    ]\n",
        "\n",
        "# Quick sanity check\n",
        "rng = make_rng()\n",
        "NUM_PORTS = CONFIG[\"num_ports\"]\n",
        "NUM_VESSELS = CONFIG[\"num_vessels\"]\n",
        "ports = initialize_ports(NUM_PORTS, CONFIG[\"docks_per_port\"], rng)\n",
        "vessels = initialize_vessels(NUM_VESSELS, NUM_PORTS, rng)\n",
        "print(\"Ports :\", ports[:2])\n",
        "print(\"Vessels:\", vessels[:2])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b433048b",
      "metadata": {},
      "source": [
        "### 4.2 Environment dynamics (vessel movement, port operations, emissions)\n",
        "We define **three step functions** that evolve the system each tick:\n",
        "1. `step_vessels()` — moves vessels along their route, burns fuel, accumulates emissions.\n",
        "2. `step_ports()` — serves queued vessels, updates dock occupancy.\n",
        "3. `compute_fuel_and_emissions()` — physics helper: fuel ∝ speed³, CO₂ ∝ fuel × emission factor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8939c9f5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------------------------------------------------------------------------\n",
        "# Physics helpers\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "def compute_fuel_and_emissions(speed: float, hours: float = 1.0) -> Tuple[float, float]:\n",
        "    \"\"\"\n",
        "    Simplified cubic fuel model (standard in maritime literature).\n",
        "    Returns (fuel_consumed_tons, co2_tons) for the given duration.\n",
        "    \"\"\"\n",
        "    k = CONFIG[\"fuel_rate_coeff\"]\n",
        "    fuel = k * (speed ** 3) * hours          # tons of fuel\n",
        "    co2  = fuel * CONFIG[\"emission_factor\"]  # tons of CO2\n",
        "    return fuel, co2\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Vessel step\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "def step_vessels(vessels: List[VesselState], dt_hours: float = 1.0) -> None:\n",
        "    \"\"\"Advance every vessel by dt_hours. Vessels at sea move toward destination.\"\"\"\n",
        "    for v in vessels:\n",
        "        if not v.at_sea:\n",
        "            continue  # vessel is docked or idle at port\n",
        "        # Distance traveled this tick\n",
        "        nm_traveled = v.speed * dt_hours\n",
        "        v.position_nm += nm_traveled\n",
        "        # Fuel & emissions\n",
        "        fuel_used, co2 = compute_fuel_and_emissions(v.speed, dt_hours)\n",
        "        v.fuel = max(v.fuel - fuel_used, 0.0)\n",
        "        v.emissions += co2\n",
        "        # Check arrival\n",
        "        leg_distance = DISTANCE_NM[v.location, v.destination]\n",
        "        if v.position_nm >= leg_distance:\n",
        "            v.position_nm = 0.0\n",
        "            v.location = v.destination\n",
        "            v.at_sea = False\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Port step\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "def step_ports(ports: List[PortState], service_rates: List[int],\n",
        "               dt_hours: float = 1.0) -> None:\n",
        "    \"\"\"Serve queued vessels at each port.\"\"\"\n",
        "    for port, rate in zip(ports, service_rates):\n",
        "        served = min(port.queue, rate)\n",
        "        port.queue = max(port.queue - served, 0)\n",
        "        port.occupied = min(port.docks, port.occupied + served)\n",
        "        port.vessels_served += served\n",
        "        # Remaining queue vessels accumulate wait time\n",
        "        port.cumulative_wait_hours += port.queue * dt_hours\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Dispatch: send a vessel from its current port to a destination\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "def dispatch_vessel(vessel: VesselState, destination: int, speed: float) -> None:\n",
        "    \"\"\"Set a vessel to depart for a new destination at a given speed.\"\"\"\n",
        "    speed = np.clip(speed, CONFIG[\"speed_min\"], CONFIG[\"speed_max\"])\n",
        "    vessel.destination = destination\n",
        "    vessel.speed = speed\n",
        "    vessel.position_nm = 0.0\n",
        "    vessel.at_sea = True\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Quick observation helper (reused by metrics and policies)\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "def observe_port_metrics(ports: List[PortState]) -> Dict[str, float]:\n",
        "    avg_queue = float(np.mean([p.queue for p in ports]))\n",
        "    dock_util = float(np.mean([p.occupied / p.docks for p in ports]))\n",
        "    total_wait = float(sum(p.cumulative_wait_hours for p in ports))\n",
        "    return {\"avg_queue\": avg_queue, \"dock_utilization\": dock_util, \"total_wait_hours\": total_wait}\n",
        "\n",
        "# Test physics\n",
        "fuel_1h, co2_1h = compute_fuel_and_emissions(speed=12.0, hours=1.0)\n",
        "print(f\"At 12 kn for 1 h → fuel={fuel_1h:.3f} t, CO₂={co2_1h:.3f} t\")\n",
        "fuel_1h_fast, co2_1h_fast = compute_fuel_and_emissions(speed=18.0, hours=1.0)\n",
        "print(f\"At 18 kn for 1 h → fuel={fuel_1h_fast:.3f} t, CO₂={co2_1h_fast:.3f} t  (×{co2_1h_fast/co2_1h:.1f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58a2369b",
      "metadata": {},
      "source": [
        "### 4.3 Gymnasium environment skeleton\n",
        "We define a `MaritimeEnv` class that follows the Gymnasium API (`reset()`, `step()`).\n",
        "This skeleton wires together the vessel movement, port operations, forecasting, and agent interfaces so that MAPPO can be plugged in later with minimal refactoring.\n",
        "\n",
        "> **Note**: We do not install Gymnasium as a dependency in the MVP — the class inherits from a simple ABC instead. Swapping to `gymnasium.Env` later requires only changing the base class and adding `observation_space` / `action_space` as proper Gymnasium `Space` objects.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2281044",
      "metadata": {},
      "outputs": [],
      "source": [
        "class MaritimeEnv:\n",
        "    \"\"\"\n",
        "    Gymnasium-style multi-agent maritime environment (MVP skeleton).\n",
        "\n",
        "    Agents\n",
        "    ------\n",
        "    - 1 Fleet Coordinator  (strategic, every `coord_freq` steps)\n",
        "    - V Vessel agents      (operational, every step)\n",
        "    - P Port agents        (operational, every step)\n",
        "\n",
        "    Observation / action shapes are intentionally kept as dicts of numpy\n",
        "    arrays so the transition to gymnasium.spaces.Dict is straightforward.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: dict = CONFIG, seed: int = SEED):\n",
        "        self.cfg = config\n",
        "        self.rng = make_rng(seed)\n",
        "        self.num_ports = config[\"num_ports\"]\n",
        "        self.num_vessels = config[\"num_vessels\"]\n",
        "        self.t = 0\n",
        "\n",
        "        # Will be populated by reset()\n",
        "        self.ports: List[PortState] = []\n",
        "        self.vessels: List[VesselState] = []\n",
        "\n",
        "        # --- Observation / action space descriptors (for MAPPO wiring) ---\n",
        "        # These describe the *shape* of each agent's obs and action vectors.\n",
        "        self.obs_shapes = {\n",
        "            \"coordinator\": (self.num_ports * config[\"medium_horizon_days\"]   # forecasts\n",
        "                            + self.num_vessels * 4                           # vessel summaries\n",
        "                            + 1),                                           # cumulative emissions\n",
        "            \"vessel\": (1 + 1 + 1 + 1                                       # location, speed, fuel, emissions\n",
        "                       + config[\"short_horizon_hours\"]                      # forecast for dest port\n",
        "                       + 3),                                                # directive (dest, window, budget)\n",
        "            \"port\": (1 + 1 + 1                                             # queue, docks, occupied\n",
        "                     + config[\"short_horizon_hours\"]                        # forecast\n",
        "                     + 1),                                                  # incoming requests\n",
        "        }\n",
        "        self.action_shapes = {\n",
        "            \"coordinator\": self.num_ports + 2,   # dest logits + window + budget\n",
        "            \"vessel\": 2,                          # speed, arrival_request\n",
        "            \"port\": 2,                            # service_rate, accept_flag\n",
        "        }\n",
        "\n",
        "    # ----- reset -----\n",
        "    def reset(self) -> Dict[str, np.ndarray]:\n",
        "        \"\"\"Reset all state and return initial observations.\"\"\"\n",
        "        self.t = 0\n",
        "        self.rng = make_rng(self.cfg[\"seed\"])\n",
        "        self.ports = initialize_ports(self.num_ports, self.cfg[\"docks_per_port\"], self.rng)\n",
        "        self.vessels = initialize_vessels(self.num_vessels, self.num_ports, self.rng)\n",
        "        return self._get_observations()\n",
        "\n",
        "    # ----- step -----\n",
        "    def step(self, actions: Dict[str, list]) -> Tuple[Dict, Dict, bool, Dict]:\n",
        "        \"\"\"\n",
        "        Execute one environment tick.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        actions : dict\n",
        "            \"coordinator\" : dict from fleet_coordinator_policy\n",
        "            \"vessels\"     : list of dicts from vessel_policy\n",
        "            \"ports\"       : list of dicts from port_policy\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        obs, rewards, done, info\n",
        "        \"\"\"\n",
        "        coord_action = actions[\"coordinator\"]\n",
        "        vessel_actions = actions[\"vessels\"]\n",
        "        port_actions = actions[\"ports\"]\n",
        "\n",
        "        # 1. Dispatch idle vessels according to coordinator directive\n",
        "        for v, va in zip(self.vessels, vessel_actions):\n",
        "            if not v.at_sea:\n",
        "                dispatch_vessel(v, coord_action[\"dest_port\"], va[\"target_speed\"])\n",
        "\n",
        "        # 2. Move vessels\n",
        "        step_vessels(self.vessels, dt_hours=1.0)\n",
        "\n",
        "        # 3. Arriving vessels join the port queue\n",
        "        for v in self.vessels:\n",
        "            if not v.at_sea and v.location == v.destination:\n",
        "                port = self.ports[v.location]\n",
        "                port.queue += 1\n",
        "\n",
        "        # 4. Ports serve vessels\n",
        "        service_rates = [pa[\"service_rate\"] for pa in port_actions]\n",
        "        step_ports(self.ports, service_rates)\n",
        "\n",
        "        # 5. Compute rewards\n",
        "        rewards = self._compute_rewards(coord_action, vessel_actions, port_actions)\n",
        "\n",
        "        self.t += 1\n",
        "        done = self.t >= self.cfg[\"rollout_steps\"]\n",
        "        obs = self._get_observations()\n",
        "        info = {\"port_metrics\": observe_port_metrics(self.ports)}\n",
        "        return obs, rewards, done, info\n",
        "\n",
        "    # ----- observations -----\n",
        "    def _get_observations(self) -> Dict[str, np.ndarray]:\n",
        "        \"\"\"Build observation vectors for every agent.\"\"\"\n",
        "        medium = medium_term_forecast(self.num_ports, self.cfg[\"medium_horizon_days\"])\n",
        "        short  = short_term_forecast(self.num_ports, self.cfg[\"short_horizon_hours\"])\n",
        "\n",
        "        # Coordinator obs: flattened medium forecast + vessel summaries + total emissions\n",
        "        vessel_summaries = np.array([\n",
        "            [v.location, v.speed, v.fuel, v.emissions] for v in self.vessels\n",
        "        ])\n",
        "        total_emissions = sum(v.emissions for v in self.vessels)\n",
        "        coord_obs = np.concatenate([\n",
        "            medium.flatten(),\n",
        "            vessel_summaries.flatten(),\n",
        "            [total_emissions],\n",
        "        ])\n",
        "\n",
        "        # Vessel obs (one per vessel)\n",
        "        vessel_obs = []\n",
        "        for v in self.vessels:\n",
        "            dest_forecast = short[v.destination] if v.destination < self.num_ports else short[0]\n",
        "            v_obs = np.concatenate([\n",
        "                [v.location, v.speed, v.fuel, v.emissions],\n",
        "                dest_forecast,\n",
        "                [0, 0, 0],  # placeholder for directive — filled by policy wrapper\n",
        "            ])\n",
        "            vessel_obs.append(v_obs)\n",
        "\n",
        "        # Port obs (one per port)\n",
        "        port_obs = []\n",
        "        for i, p in enumerate(self.ports):\n",
        "            p_obs = np.concatenate([\n",
        "                [p.queue, p.docks, p.occupied],\n",
        "                short[i],\n",
        "                [0],  # incoming requests — filled by policy wrapper\n",
        "            ])\n",
        "            port_obs.append(p_obs)\n",
        "\n",
        "        return {\n",
        "            \"coordinator\": coord_obs,\n",
        "            \"vessels\": vessel_obs,\n",
        "            \"ports\": port_obs,\n",
        "        }\n",
        "\n",
        "    # ----- rewards (placeholder, see §7 for full definitions) -----\n",
        "    def _compute_rewards(self, coord_action, vessel_actions, port_actions) -> Dict:\n",
        "        \"\"\"Compute per-agent rewards. Detailed formulas in §7.\"\"\"\n",
        "        vessel_rewards = [\n",
        "            compute_vessel_reward(v) for v in self.vessels\n",
        "        ]\n",
        "        port_rewards = [\n",
        "            compute_port_reward(p) for p in self.ports\n",
        "        ]\n",
        "        coord_reward = compute_coordinator_reward(self.vessels, self.ports)\n",
        "        return {\n",
        "            \"coordinator\": coord_reward,\n",
        "            \"vessels\": vessel_rewards,\n",
        "            \"ports\": port_rewards,\n",
        "        }\n",
        "\n",
        "    # ----- centralized critic state (CTDE, §2.3) -----\n",
        "    def get_global_state(self) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Concatenate all agent observations + global stats into a single\n",
        "        vector for the centralized critic during MAPPO training.\n",
        "        \"\"\"\n",
        "        obs = self._get_observations()\n",
        "        global_congestion = np.array([p.queue for p in self.ports], dtype=float)\n",
        "        total_emissions = np.array([sum(v.emissions for v in self.vessels)])\n",
        "        return np.concatenate([\n",
        "            obs[\"coordinator\"],\n",
        "            *obs[\"vessels\"],\n",
        "            *obs[\"ports\"],\n",
        "            global_congestion,\n",
        "            total_emissions,\n",
        "        ])\n",
        "\n",
        "# Instantiate and test reset\n",
        "env = MaritimeEnv()\n",
        "obs = env.reset()\n",
        "print(\"Coordinator obs shape:\", obs[\"coordinator\"].shape)\n",
        "print(\"Vessel 0 obs shape:   \", obs[\"vessels\"][0].shape)\n",
        "print(\"Port 0 obs shape:     \", obs[\"ports\"][0].shape)\n",
        "print(\"Global state shape:   \", env.get_global_state().shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b011c5a",
      "metadata": {},
      "source": [
        "## 5. Forecasting module (mock)\n",
        "The **medium-term forecaster** provides a 3–7 day congestion estimate for each port. The **short-term forecaster** outputs 6–24 hour predictions. Here we mock them with noisy trends to validate the data flow."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d356754",
      "metadata": {},
      "source": [
        "### 5.1 Forecast ablation hooks\n",
        "We will test the value of forecasting via controlled ablations:\n",
        "- **Horizon sweep**: short (6h), medium (12h), long (24h)\n",
        "- **Accuracy sweep**: add calibrated noise to forecasts\n",
        "- **Oracle vs learned**: perfect vs model-predicted congestion\n",
        "- **Sharing**: coordinator-only vs shared with vessels/ports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d39c48b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "def medium_term_forecast(num_ports: int, horizon_days: int = 5) -> np.ndarray:\n",
        "    base = rng.uniform(2, 8, size=(num_ports, 1))\n",
        "    trend = np.linspace(0, 1.5, horizon_days)[None, :]\n",
        "    noise = rng.normal(0, 0.3, size=(num_ports, horizon_days))\n",
        "    return np.clip(base + trend + noise, 0, None)\n",
        "\n",
        "def short_term_forecast(num_ports: int, horizon_hours: int = 12) -> np.ndarray:\n",
        "    base = rng.uniform(1, 6, size=(num_ports, 1))\n",
        "    noise = rng.normal(0, 0.5, size=(num_ports, horizon_hours))\n",
        "    return np.clip(base + noise, 0, None)\n",
        "\n",
        "medium_forecast = medium_term_forecast(NUM_PORTS, horizon_days=CONFIG[\"medium_horizon_days\"])\n",
        "short_forecast = short_term_forecast(NUM_PORTS, horizon_hours=CONFIG[\"short_horizon_hours\"])\n",
        "medium_forecast.shape, short_forecast.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "078cb39c",
      "metadata": {},
      "source": [
        "## 6. Agent decision stubs (hierarchical control)\n",
        "We create placeholder policies that **consume forecasts** and **emit actions**. These are not learned yet; they simply show the flow of information and will be replaced with MAPPO policies later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a0d556a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def fleet_coordinator_policy(medium_forecast: np.ndarray,\n",
        "                            vessels: List[VesselState]) -> Dict:\n",
        "    \"\"\"\n",
        "    Strategic policy: pick the least-congested port and set an emission budget.\n",
        "    Consumes medium-term forecast (RQ1, RQ3).\n",
        "    \"\"\"\n",
        "    port_scores = medium_forecast.mean(axis=1)\n",
        "    dest_port = int(np.argmin(port_scores))\n",
        "    total_emissions = sum(v.emissions for v in vessels)\n",
        "    return {\n",
        "        \"dest_port\": dest_port,\n",
        "        \"departure_window_hours\": 12,\n",
        "        \"emission_budget\": max(50.0 - total_emissions * 0.1, 10.0),\n",
        "    }\n",
        "\n",
        "def vessel_policy(vessel: VesselState, short_forecast: np.ndarray,\n",
        "                  directive: Dict) -> Dict:\n",
        "    \"\"\"\n",
        "    Operational policy: adjust speed based on congestion forecast (RQ1).\n",
        "    Reduces speed when destination port is congested to save fuel/emissions.\n",
        "    \"\"\"\n",
        "    dest_port = directive[\"dest_port\"]\n",
        "    congestion = float(short_forecast[dest_port].mean())\n",
        "    # Slow down if congestion is high (slow-steaming to wait out the queue)\n",
        "    if congestion > 5.0:\n",
        "        speed = CONFIG[\"speed_min\"]\n",
        "    elif congestion > 3.0:\n",
        "        speed = CONFIG[\"nominal_speed\"]\n",
        "    else:\n",
        "        speed = CONFIG[\"speed_max\"]\n",
        "    return {\n",
        "        \"target_speed\": speed,\n",
        "        \"request_arrival_slot\": True,\n",
        "    }\n",
        "\n",
        "def port_policy(port_state: PortState, incoming_requests: int,\n",
        "                short_forecast_row: np.ndarray) -> Dict:\n",
        "    \"\"\"\n",
        "    Port policy: adjust service rate based on predicted pressure (RQ1).\n",
        "    Opens all docks when near-term congestion is forecast to be high.\n",
        "    \"\"\"\n",
        "    pressure = float(short_forecast_row.mean())\n",
        "    if pressure > 4.0:\n",
        "        service_rate = port_state.docks  # full capacity\n",
        "    elif port_state.queue > 2:\n",
        "        service_rate = min(port_state.docks, port_state.queue)\n",
        "    else:\n",
        "        service_rate = min(port_state.docks, port_state.occupied + 1)\n",
        "    return {\n",
        "        \"service_rate\": service_rate,\n",
        "        \"accept_requests\": min(incoming_requests, port_state.docks - port_state.occupied),\n",
        "    }\n",
        "\n",
        "# ------ Quick test of the full hierarchy ------\n",
        "rng = make_rng()\n",
        "ports = initialize_ports(NUM_PORTS, CONFIG[\"docks_per_port\"], rng)\n",
        "vessels = initialize_vessels(NUM_VESSELS, NUM_PORTS, rng)\n",
        "medium_forecast = medium_term_forecast(NUM_PORTS, CONFIG[\"medium_horizon_days\"])\n",
        "short_forecast  = short_term_forecast(NUM_PORTS, CONFIG[\"short_horizon_hours\"])\n",
        "\n",
        "directive = fleet_coordinator_policy(medium_forecast, vessels)\n",
        "v_actions = [vessel_policy(v, short_forecast, directive) for v in vessels]\n",
        "incoming  = sum(1 for a in v_actions if a[\"request_arrival_slot\"])\n",
        "p_actions = [port_policy(p, incoming, short_forecast[i]) for i, p in enumerate(ports)]\n",
        "\n",
        "# Dispatch vessels and step\n",
        "for v, va in zip(vessels, v_actions):\n",
        "    dispatch_vessel(v, directive[\"dest_port\"], va[\"target_speed\"])\n",
        "step_vessels(vessels, dt_hours=1.0)\n",
        "step_ports(ports, [a[\"service_rate\"] for a in p_actions])\n",
        "\n",
        "print(\"Directive:\", directive)\n",
        "print(\"Vessel 0 action:\", v_actions[0])\n",
        "print(\"Port 0 action:  \", p_actions[0])\n",
        "print(\"Port metrics:   \", observe_port_metrics(ports))\n",
        "print(\"Vessel 0 emissions:\", f\"{vessels[0].emissions:.4f} t CO₂\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "334ccae3",
      "metadata": {},
      "source": [
        "## 7. Reward functions\n",
        "We implement the three per-agent reward functions from the MDP formulation (§2.1):\n",
        "- **Coordinator**: $R_C = -(\\text{voyage cost} + \\lambda \\cdot \\text{emission penalty})$\n",
        "- **Vessel**: $R_V = -(\\alpha \\cdot \\text{Fuel}(v) + \\beta \\cdot \\text{Delay} + \\gamma \\cdot \\text{Emissions}(v))$\n",
        "- **Port**: $R_P = -(\\text{Queue wait time} + \\text{Dock idle time})$\n",
        "\n",
        "These are the negative-cost rewards used by PPO/MAPPO during training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bacdb380",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------------------------------------------------------------------------\n",
        "# Vessel reward: R_V = -(α·Fuel + β·Delay + γ·Emissions)\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "def compute_vessel_reward(vessel: VesselState) -> float:\n",
        "    \"\"\"Per-step vessel reward (negative cost).\"\"\"\n",
        "    fuel_used, co2 = compute_fuel_and_emissions(vessel.speed, hours=1.0)\n",
        "    fuel_cost     = CONFIG[\"fuel_weight\"]     * fuel_used\n",
        "    delay_cost    = CONFIG[\"delay_weight\"]     * vessel.delay_hours\n",
        "    emission_cost = CONFIG[\"emission_weight\"]  * co2\n",
        "    return -(fuel_cost + delay_cost + emission_cost)\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Port reward: R_P = -(queue wait + dock idle)\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "def compute_port_reward(port: PortState) -> float:\n",
        "    \"\"\"Per-step port reward (negative cost).\"\"\"\n",
        "    queue_penalty = float(port.queue)       # penalize long queues\n",
        "    idle_docks    = max(port.docks - port.occupied, 0)\n",
        "    idle_penalty  = CONFIG[\"dock_idle_weight\"] * idle_docks\n",
        "    return -(queue_penalty + idle_penalty)\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Coordinator reward: R_C = -(voyage cost + λ·emission penalty)\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "def compute_coordinator_reward(vessels: List[VesselState],\n",
        "                               ports: List[PortState]) -> float:\n",
        "    \"\"\"System-level coordinator reward (negative cost).\"\"\"\n",
        "    total_fuel_cost = sum(\n",
        "        compute_fuel_and_emissions(v.speed, 1.0)[0] for v in vessels\n",
        "    )\n",
        "    total_emissions = sum(v.emissions for v in vessels)\n",
        "    avg_queue = float(np.mean([p.queue for p in ports]))\n",
        "    emission_penalty = CONFIG[\"emission_lambda\"] * total_emissions\n",
        "    voyage_cost = total_fuel_cost + avg_queue\n",
        "    return -(voyage_cost + emission_penalty)\n",
        "\n",
        "# ------ Test all three rewards ------\n",
        "print(\"Vessel 0 reward:\", f\"{compute_vessel_reward(vessels[0]):.4f}\")\n",
        "print(\"Port 0 reward:  \", f\"{compute_port_reward(ports[0]):.4f}\")\n",
        "print(\"Coordinator reward:\", f\"{compute_coordinator_reward(vessels, ports):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db4e64aa",
      "metadata": {},
      "source": [
        "## 8. Metrics and evaluation hooks\n",
        "We implement the full set of metrics from the proposal (§6.3), covering forecasting, agent performance, coordination quality, and economic impact (RQ4).\n",
        "\n",
        "### 8.1 Forecasting, agent, coordination, and economic metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be20ff42",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =====================================================================\n",
        "# FORECASTING METRICS\n",
        "# =====================================================================\n",
        "\n",
        "def forecast_mae(predicted: np.ndarray, actual: np.ndarray) -> float:\n",
        "    \"\"\"Mean Absolute Error between forecast and realized congestion.\"\"\"\n",
        "    return float(np.mean(np.abs(predicted - actual)))\n",
        "\n",
        "def forecast_rmse(predicted: np.ndarray, actual: np.ndarray) -> float:\n",
        "    \"\"\"Root Mean Squared Error between forecast and realized congestion.\"\"\"\n",
        "    return float(np.sqrt(np.mean((predicted - actual) ** 2)))\n",
        "\n",
        "# =====================================================================\n",
        "# VESSEL METRICS\n",
        "# =====================================================================\n",
        "\n",
        "def compute_vessel_metrics(vessels: List[VesselState]) -> Dict[str, float]:\n",
        "    \"\"\"Comprehensive vessel-level metrics.\"\"\"\n",
        "    avg_speed      = float(np.mean([v.speed for v in vessels]))\n",
        "    avg_fuel       = float(np.mean([v.fuel for v in vessels]))\n",
        "    total_fuel_used = float(sum(100.0 - v.fuel for v in vessels))\n",
        "    total_emissions = float(sum(v.emissions for v in vessels))\n",
        "    avg_delay      = float(np.mean([v.delay_hours for v in vessels]))\n",
        "    # On-time rate: fraction of vessels with delay < 2 h (threshold)\n",
        "    on_time_count  = sum(1 for v in vessels if v.delay_hours < 2.0)\n",
        "    on_time_rate   = on_time_count / len(vessels) if vessels else 0.0\n",
        "    return {\n",
        "        \"avg_speed\": avg_speed,\n",
        "        \"avg_fuel_remaining\": avg_fuel,\n",
        "        \"total_fuel_used\": total_fuel_used,\n",
        "        \"total_emissions_co2\": total_emissions,\n",
        "        \"avg_delay_hours\": avg_delay,\n",
        "        \"on_time_rate\": on_time_rate,\n",
        "    }\n",
        "\n",
        "# =====================================================================\n",
        "# PORT METRICS\n",
        "# =====================================================================\n",
        "\n",
        "def compute_port_metrics(ports: List[PortState]) -> Dict[str, float]:\n",
        "    \"\"\"Comprehensive port-level metrics.\"\"\"\n",
        "    avg_queue    = float(np.mean([p.queue for p in ports]))\n",
        "    dock_util    = float(np.mean([p.occupied / p.docks for p in ports]))\n",
        "    total_wait   = float(sum(p.cumulative_wait_hours for p in ports))\n",
        "    total_served = int(sum(p.vessels_served for p in ports))\n",
        "    avg_wait_per = total_wait / total_served if total_served > 0 else 0.0\n",
        "    return {\n",
        "        \"avg_queue\": avg_queue,\n",
        "        \"dock_utilization\": dock_util,\n",
        "        \"total_wait_hours\": total_wait,\n",
        "        \"total_vessels_served\": total_served,\n",
        "        \"avg_wait_per_vessel\": avg_wait_per,\n",
        "    }\n",
        "\n",
        "# =====================================================================\n",
        "# COORDINATION METRICS\n",
        "# =====================================================================\n",
        "\n",
        "def compute_coordination_metrics(v_actions: List[Dict],\n",
        "                                 p_actions: List[Dict]) -> Dict[str, float]:\n",
        "    \"\"\"Measure coordination quality between vessels and ports.\"\"\"\n",
        "    total_requests = sum(1 for a in v_actions if a[\"request_arrival_slot\"])\n",
        "    total_accepted = sum(a.get(\"accept_requests\", 0) for a in p_actions)\n",
        "    agreement_rate = total_accepted / total_requests if total_requests > 0 else 0.0\n",
        "    return {\n",
        "        \"total_vessel_requests\": total_requests,\n",
        "        \"total_port_accepted\": total_accepted,\n",
        "        \"policy_agreement_rate\": agreement_rate,\n",
        "    }\n",
        "\n",
        "# =====================================================================\n",
        "# ECONOMIC METRICS (RQ4)\n",
        "# =====================================================================\n",
        "\n",
        "def compute_economic_metrics(vessels: List[VesselState],\n",
        "                             ports: List[PortState]) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Estimate economic impact of coordination (RQ4).\n",
        "    Captures fuel cost, delay penalties, carbon cost, and effective\n",
        "    shipping price per vessel.\n",
        "    \"\"\"\n",
        "    fuel_cost_total = sum(\n",
        "        (100.0 - v.fuel) * CONFIG[\"fuel_price_per_ton\"] for v in vessels\n",
        "    )\n",
        "    delay_cost_total = sum(\n",
        "        v.delay_hours * CONFIG[\"delay_penalty_per_hour\"] for v in vessels\n",
        "    )\n",
        "    carbon_cost_total = sum(\n",
        "        v.emissions * CONFIG[\"carbon_price_per_ton\"] for v in vessels\n",
        "    )\n",
        "    total_ops_cost = fuel_cost_total + delay_cost_total + carbon_cost_total\n",
        "\n",
        "    # Effective shipping price = ops cost divided across fleet\n",
        "    n = len(vessels)\n",
        "    price_per_vessel = total_ops_cost / n if n > 0 else 0.0\n",
        "\n",
        "    # Reliability = fraction of cargo value NOT consumed by ops costs\n",
        "    cargo_total = n * CONFIG[\"cargo_value_per_vessel\"]\n",
        "    reliability = 1.0 - (total_ops_cost / cargo_total) if cargo_total > 0 else 0.0\n",
        "\n",
        "    return {\n",
        "        \"fuel_cost_usd\": fuel_cost_total,\n",
        "        \"delay_cost_usd\": delay_cost_total,\n",
        "        \"carbon_cost_usd\": carbon_cost_total,\n",
        "        \"total_ops_cost_usd\": total_ops_cost,\n",
        "        \"price_per_vessel_usd\": price_per_vessel,\n",
        "        \"cost_reliability\": reliability,\n",
        "    }\n",
        "\n",
        "# ------ Test all metric groups ------\n",
        "v_metrics = compute_vessel_metrics(vessels)\n",
        "p_metrics = compute_port_metrics(ports)\n",
        "c_metrics = compute_coordination_metrics(v_actions, p_actions)\n",
        "e_metrics = compute_economic_metrics(vessels, ports)\n",
        "\n",
        "print(\"Vessel metrics:      \", v_metrics)\n",
        "print(\"Port metrics:        \", p_metrics)\n",
        "print(\"Coordination metrics:\", c_metrics)\n",
        "print(\"Economic metrics:    \", {k: f\"{v:,.2f}\" for k, v in e_metrics.items()})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a37144c",
      "metadata": {},
      "source": [
        "## 9. Experiment protocol and baselines\n",
        "Each experiment run follows a consistent protocol:\n",
        "1. `reset()` — initialize environment, ports, vessels (with a controlled seed).\n",
        "2. Generate forecasts (or use oracle / zero-noise variants).\n",
        "3. Execute coordination loop: coordinator → vessels → ports.\n",
        "4. Log **all** metrics: vessel, port, coordination, economic, rewards.\n",
        "5. Repeat over N episodes and compare against baselines.\n",
        "\n",
        "**Baselines** (addressing RQ2):\n",
        "| Label | Coordination | Forecasts | Description |\n",
        "|-------|-------------|-----------|-------------|\n",
        "| **Independent** | None | None | Each agent acts alone, no message passing |\n",
        "| **Reactive** | Yes | None | Agents coordinate but only use current state |\n",
        "| **Forecast** | Yes | Learned | Agents use medium + short-term forecasts (proposed) |\n",
        "| **Oracle** | Yes | Perfect | Agents see true future congestion (upper bound) |\n",
        "\n",
        "### 9.1 Ablation runner framework\n",
        "We define a parameterized `run_experiment()` that sweeps over policy types, forecast horizons, and noise levels to support controlled ablation studies (RQ3).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a44c0b59",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =====================================================================\n",
        "# Ablation runner — parameterized experiment loop\n",
        "# =====================================================================\n",
        "\n",
        "def run_experiment(\n",
        "    policy_type: str = \"forecast\",   # \"independent\", \"reactive\", \"forecast\", \"oracle\"\n",
        "    forecast_horizon: int = 12,      # short-term horizon (hours)\n",
        "    forecast_noise: float = 0.5,     # std of Gaussian noise added to forecasts\n",
        "    share_forecasts: bool = True,    # whether vessels/ports see forecasts\n",
        "    steps: int = 20,\n",
        "    seed: int = SEED,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Run one experiment episode and return a per-step log DataFrame.\n",
        "\n",
        "    Policy types\n",
        "    ------------\n",
        "    - independent : no coordination, no forecasts, nominal speed\n",
        "    - reactive    : coordination via current state only (no forecasts)\n",
        "    - forecast    : coordination with noisy learned forecasts (proposed)\n",
        "    - oracle      : coordination with perfect (noise-free) forecasts (upper bound)\n",
        "    \"\"\"\n",
        "    rng_exp = make_rng(seed)\n",
        "    ports_exp   = initialize_ports(NUM_PORTS, CONFIG[\"docks_per_port\"], rng_exp)\n",
        "    vessels_exp = initialize_vessels(NUM_VESSELS, NUM_PORTS, rng_exp)\n",
        "    log = []\n",
        "\n",
        "    for t in range(steps):\n",
        "        # --- Generate forecasts ---\n",
        "        noise_scale = 0.0 if policy_type == \"oracle\" else forecast_noise\n",
        "        medium = medium_term_forecast(NUM_PORTS, CONFIG[\"medium_horizon_days\"])\n",
        "        short  = short_term_forecast(NUM_PORTS, forecast_horizon)\n",
        "        if noise_scale > 0:\n",
        "            medium += rng_exp.normal(0, noise_scale, medium.shape)\n",
        "            short  += rng_exp.normal(0, noise_scale, short.shape)\n",
        "            medium = np.clip(medium, 0, None)\n",
        "            short  = np.clip(short, 0, None)\n",
        "\n",
        "        # --- Coordinator ---\n",
        "        if policy_type == \"independent\":\n",
        "            # Random destination, no coordination\n",
        "            directive = {\n",
        "                \"dest_port\": int(rng_exp.integers(0, NUM_PORTS)),\n",
        "                \"departure_window_hours\": 12,\n",
        "                \"emission_budget\": 50.0,\n",
        "            }\n",
        "        else:\n",
        "            directive = fleet_coordinator_policy(medium, vessels_exp)\n",
        "\n",
        "        # --- Vessel policies ---\n",
        "        if policy_type == \"independent\":\n",
        "            v_actions = [{\"target_speed\": CONFIG[\"nominal_speed\"],\n",
        "                          \"request_arrival_slot\": False} for _ in vessels_exp]\n",
        "        elif policy_type == \"reactive\":\n",
        "            v_actions = [{\"target_speed\": CONFIG[\"nominal_speed\"],\n",
        "                          \"request_arrival_slot\": True} for _ in vessels_exp]\n",
        "        else:\n",
        "            use_forecast = short if share_forecasts else np.zeros_like(short)\n",
        "            v_actions = [vessel_policy(v, use_forecast, directive) for v in vessels_exp]\n",
        "\n",
        "        # --- Dispatch idle vessels ---\n",
        "        for v, va in zip(vessels_exp, v_actions):\n",
        "            if not v.at_sea:\n",
        "                dispatch_vessel(v, directive[\"dest_port\"], va[\"target_speed\"])\n",
        "\n",
        "        # --- Step physics ---\n",
        "        step_vessels(vessels_exp, dt_hours=1.0)\n",
        "\n",
        "        # Arriving vessels join queue\n",
        "        for v in vessels_exp:\n",
        "            if not v.at_sea and v.location == v.destination:\n",
        "                ports_exp[v.location].queue += 1\n",
        "\n",
        "        # --- Port policies ---\n",
        "        incoming = sum(1 for a in v_actions if a.get(\"request_arrival_slot\", False))\n",
        "        if policy_type == \"independent\":\n",
        "            p_actions = [{\"service_rate\": 1, \"accept_requests\": 0} for _ in ports_exp]\n",
        "        else:\n",
        "            use_forecast_port = short if share_forecasts else np.zeros_like(short)\n",
        "            p_actions = [\n",
        "                port_policy(p, incoming, use_forecast_port[i])\n",
        "                for i, p in enumerate(ports_exp)\n",
        "            ]\n",
        "        step_ports(ports_exp, [a[\"service_rate\"] for a in p_actions])\n",
        "\n",
        "        # --- Log metrics ---\n",
        "        v_m = compute_vessel_metrics(vessels_exp)\n",
        "        p_m = compute_port_metrics(ports_exp)\n",
        "        c_m = compute_coordination_metrics(v_actions, p_actions)\n",
        "        e_m = compute_economic_metrics(vessels_exp, ports_exp)\n",
        "        rewards_v = [compute_vessel_reward(v) for v in vessels_exp]\n",
        "        rewards_p = [compute_port_reward(p) for p in ports_exp]\n",
        "        reward_c  = compute_coordinator_reward(vessels_exp, ports_exp)\n",
        "\n",
        "        log.append({\n",
        "            \"t\": t,\n",
        "            \"policy\": policy_type,\n",
        "            \"forecast_horizon\": forecast_horizon,\n",
        "            \"forecast_noise\": forecast_noise,\n",
        "            **v_m, **p_m, **c_m, **e_m,\n",
        "            \"avg_vessel_reward\": float(np.mean(rewards_v)),\n",
        "            \"avg_port_reward\": float(np.mean(rewards_p)),\n",
        "            \"coordinator_reward\": reward_c,\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(log)\n",
        "\n",
        "# ------ Quick validation ------\n",
        "df_test = run_experiment(policy_type=\"forecast\", steps=5, seed=42)\n",
        "print(\"Columns:\", list(df_test.columns))\n",
        "df_test.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9c07ae1",
      "metadata": {},
      "source": [
        "## 10. MVP execution and visualization\n",
        "We run the ablation runner across all four baseline policies to show the end-to-end pipeline and compare outcomes (RQ2). This is **not** learned training — it uses the policy stubs to validate wiring before integrating MAPPO.\n",
        "\n",
        "### 10.1 Rollout with full pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30eaab3b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run all four baseline policies\n",
        "STEPS = CONFIG[\"rollout_steps\"]\n",
        "\n",
        "results = {}\n",
        "for policy in [\"independent\", \"reactive\", \"forecast\", \"oracle\"]:\n",
        "    results[policy] = run_experiment(policy_type=policy, steps=STEPS, seed=SEED)\n",
        "\n",
        "# Combine into one DataFrame for easy comparison\n",
        "all_results = pd.concat(results.values(), ignore_index=True)\n",
        "\n",
        "# Show summary: final-step metrics per policy\n",
        "summary = (\n",
        "    all_results\n",
        "    .groupby(\"policy\")\n",
        "    .agg({\n",
        "        \"avg_queue\": \"mean\",\n",
        "        \"dock_utilization\": \"mean\",\n",
        "        \"total_emissions_co2\": \"last\",\n",
        "        \"total_fuel_used\": \"last\",\n",
        "        \"on_time_rate\": \"mean\",\n",
        "        \"total_ops_cost_usd\": \"last\",\n",
        "        \"cost_reliability\": \"last\",\n",
        "        \"avg_vessel_reward\": \"mean\",\n",
        "        \"coordinator_reward\": \"mean\",\n",
        "        \"policy_agreement_rate\": \"mean\",\n",
        "    })\n",
        "    .round(3)\n",
        ")\n",
        "summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43fb7d43",
      "metadata": {},
      "source": [
        "### 10.2 Visualization: comparative plots across all baselines\n",
        "We compare all four policies across key dimensions to validate that the hierarchy and forecasts have the expected effect.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af258075",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 3, figsize=(16, 9))\n",
        "fig.suptitle(\"Policy Comparison — MVP Baselines (RQ2)\", fontsize=14)\n",
        "\n",
        "metrics_to_plot = [\n",
        "    (\"avg_queue\",           \"Avg Queue Length\",        \"Queue\"),\n",
        "    (\"dock_utilization\",    \"Dock Utilization\",        \"Utilization\"),\n",
        "    (\"total_emissions_co2\", \"Cumulative CO₂ (tons)\",   \"CO₂\"),\n",
        "    (\"total_fuel_used\",     \"Cumulative Fuel (tons)\",   \"Fuel\"),\n",
        "    (\"avg_vessel_reward\",   \"Avg Vessel Reward\",        \"Reward\"),\n",
        "    (\"total_ops_cost_usd\",  \"Total Ops Cost (USD)\",     \"Cost ($)\"),\n",
        "]\n",
        "\n",
        "for ax, (col, title, ylabel) in zip(axes.flat, metrics_to_plot):\n",
        "    for policy in [\"independent\", \"reactive\", \"forecast\", \"oracle\"]:\n",
        "        df = results[policy]\n",
        "        ax.plot(df[\"t\"], df[col], label=policy)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(\"Step\")\n",
        "    ax.set_ylabel(ylabel)\n",
        "    ax.legend(fontsize=8)\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62f88c25",
      "metadata": {},
      "source": [
        "### 10.3 Ablation: forecast horizon sweep (RQ3)\n",
        "We sweep over different short-term forecast horizons to test which granularity best supports vessel/port decisions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17e54b90",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------- Horizon sweep ----------\n",
        "horizons = [6, 12, 24]\n",
        "horizon_results = {}\n",
        "for h in horizons:\n",
        "    horizon_results[h] = run_experiment(\n",
        "        policy_type=\"forecast\", forecast_horizon=h, steps=STEPS, seed=SEED\n",
        "    )\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "fig.suptitle(\"Forecast Horizon Ablation (RQ3)\", fontsize=13)\n",
        "\n",
        "for ax, (col, title) in zip(axes, [\n",
        "    (\"avg_queue\", \"Avg Queue\"),\n",
        "    (\"total_emissions_co2\", \"Cumulative CO₂\"),\n",
        "    (\"total_ops_cost_usd\", \"Total Ops Cost ($)\"),\n",
        "]):\n",
        "    for h in horizons:\n",
        "        df = horizon_results[h]\n",
        "        ax.plot(df[\"t\"], df[col], label=f\"{h}h\")\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(\"Step\")\n",
        "    ax.legend()\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
        "plt.show()\n",
        "\n",
        "# ---------- Noise sweep ----------\n",
        "noise_levels = [0.0, 0.3, 0.5, 1.0, 2.0]\n",
        "noise_results = {}\n",
        "for n in noise_levels:\n",
        "    noise_results[n] = run_experiment(\n",
        "        policy_type=\"forecast\", forecast_noise=n, steps=STEPS, seed=SEED\n",
        "    )\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "fig.suptitle(\"Forecast Noise Ablation (RQ3)\", fontsize=13)\n",
        "\n",
        "for ax, (col, title) in zip(axes, [\n",
        "    (\"avg_queue\", \"Avg Queue\"),\n",
        "    (\"total_emissions_co2\", \"Cumulative CO₂\"),\n",
        "    (\"total_ops_cost_usd\", \"Total Ops Cost ($)\"),\n",
        "]):\n",
        "    for n in noise_levels:\n",
        "        df = noise_results[n]\n",
        "        ax.plot(df[\"t\"], df[col], label=f\"σ={n}\")\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(\"Step\")\n",
        "    ax.legend()\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
        "plt.show()\n",
        "\n",
        "# ---------- Sharing ablation ----------\n",
        "sharing_configs = {\"shared\": True, \"coordinator_only\": False}\n",
        "sharing_results = {}\n",
        "for label, share in sharing_configs.items():\n",
        "    sharing_results[label] = run_experiment(\n",
        "        policy_type=\"forecast\", share_forecasts=share, steps=STEPS, seed=SEED\n",
        "    )\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
        "fig.suptitle(\"Forecast Sharing Ablation (RQ3)\", fontsize=13)\n",
        "for label in sharing_configs:\n",
        "    df = sharing_results[label]\n",
        "    ax[0].plot(df[\"t\"], df[\"avg_queue\"], label=label)\n",
        "    ax[1].plot(df[\"t\"], df[\"total_ops_cost_usd\"], label=label)\n",
        "ax[0].set_title(\"Avg Queue\"); ax[0].legend()\n",
        "ax[1].set_title(\"Total Ops Cost ($)\"); ax[1].legend()\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1195d520",
      "metadata": {},
      "source": [
        "## 11. MVP-to-Research checklist\n",
        "This checklist traces what is **covered** in the MVP versus what remains for the research-grade implementation.\n",
        "\n",
        "| Component | MVP status | Research-grade upgrade |\n",
        "|-----------|-----------|----------------------|\n",
        "| Agent hierarchy (coordinator → vessel → port) | ✅ Implemented | Add learned policies via MAPPO |\n",
        "| Vessel movement & transit model | ✅ Distance matrix + step_vessels | Add weather, routing alternatives |\n",
        "| Fuel consumption (cubic model) | ✅ Implemented | Calibrate with AIS data |\n",
        "| CO₂ emissions + budget tracking | ✅ Implemented | Add ECA zones, scrubber effects |\n",
        "| Per-agent reward functions (R_C, R_V, R_P) | ✅ Implemented | Tune weights via hyperparameter search |\n",
        "| Gymnasium env skeleton (reset/step) | ✅ Implemented | Swap ABC → gymnasium.Env, add Spaces |\n",
        "| Centralized critic (CTDE) | ✅ Global state concatenation stub | Wire into MAPPO shared critic |\n",
        "| Medium + short-term forecasting | ✅ Mock (noisy trends) | Replace with RNN / econometric models |\n",
        "| Forecast ablations (horizon, noise, sharing) | ✅ Parameterized runner | Run at scale with learned models |\n",
        "| Baseline comparison (4 policies) | ✅ Independent/reactive/forecast/oracle | Add heuristic baselines |\n",
        "| Vessel metrics (fuel, delay, on-time rate) | ✅ Implemented | Add per-trip breakdown |\n",
        "| Port metrics (queue, util, wait time) | ✅ Implemented | Add throughput, turnaround time |\n",
        "| Coordination metrics (agreement rate) | ✅ Implemented | Add communication overhead |\n",
        "| Economic metrics (cost, reliability, RQ4) | ✅ Implemented | Calibrate with shipping market data |\n",
        "| RQ traceability | ✅ Annotated in code and markdown | Formal experiment → RQ mapping |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "681f3fa9",
      "metadata": {},
      "source": [
        "## 12. Next steps for the full project\n",
        "\n",
        "### Month 2 (March) — Forecasting & baselines\n",
        "1. **Replace mock forecasts** with trained models (RNN for short-term, econometric for medium-term).\n",
        "2. **Validate forecast accuracy** using MAE/RMSE on synthetic + AIS data.\n",
        "3. **Implement heuristic baselines** (FCFS port scheduling, constant-speed vessels).\n",
        "\n",
        "### Month 3 (April) — MAPPO training\n",
        "4. **Swap `MaritimeEnv` base class** to `gymnasium.Env` with proper `observation_space` / `action_space`.\n",
        "5. **Implement MAPPO** (Multi-Agent PPO) with centralized critic using the `get_global_state()` method.\n",
        "6. **Train coordinated agents** under reactive and forecast-informed settings.\n",
        "7. **Debug reward shaping** and inter-agent communication protocols.\n",
        "\n",
        "### Month 4 (May) — Ablations & evaluation\n",
        "8. **Run full ablation studies**: horizon sweep, noise sweep, sharing modes, centralized vs decentralized.\n",
        "9. **Compare all baselines** (independent, reactive, heuristic, forecast, oracle) using the metric suite.\n",
        "10. **Analyze economic impact** (RQ4): shipping cost variability, price reliability.\n",
        "11. **Compile results** and prepare the final report and VIP presentation.\n",
        "\n",
        "This MVP provides a **complete, executable foundation** covering agent hierarchy, physical dynamics, reward functions, metrics, and ablation infrastructure. The transition to research-grade requires swapping stubs for learned components while keeping the same evaluation pipeline.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "mvp_hmarl_maritime.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
