# Weather-enabled experiment with curriculum training.
# Usage: python scripts/run_experiment.py configs/weather_curriculum.yaml

name: weather_curriculum
description: >
  Progressive curriculum training that ramps weather severity from
  calm to full storm conditions over four stages.
tags:
  - weather
  - curriculum
  - progressive

env:
  num_vessels: 3
  num_ports: 2
  docks_per_port: 3
  rollout_steps: 55
  weather_enabled: true
  weather_penalty_factor: 0.15

mappo:
  lr: 0.0003                   # initial Adam learning rate
  lr_end: 0.00005               # linearly anneal LR to this value
  rollout_length: 50            # steps per rollout before PPO update
  num_epochs: 4                 # PPO epochs per update
  minibatch_size: 128           # samples per PPO minibatch
  clip_eps: 0.2                 # PPO clipping epsilon
  gamma: 0.99                   # discount factor
  gae_lambda: 0.95              # GAE lambda for advantage estimation
  hidden_dims: [64, 64]         # actor-critic MLP hidden layer sizes
  normalize_observations: true
  normalize_rewards: true

curriculum_stages:              # progressive weather severity ramp
  - fraction: 0.0
    config_overrides:
      weather_enabled: false
  - fraction: 0.25
    config_overrides:
      weather_enabled: true
      weather_penalty_factor: 0.05
  - fraction: 0.50
    config_overrides:
      weather_enabled: true
      weather_penalty_factor: 0.10
  - fraction: 0.75
    config_overrides:
      weather_enabled: true
      weather_penalty_factor: 0.15

num_iterations: 300
num_seeds: 3
eval_interval: 25
early_stopping_patience: 40
output_dir: runs/weather_curriculum
tensorboard: false
console_log: true
log_every: 10
