# Multi-seed experiment â€” 5 seeds for statistical evaluation.
# Usage: python scripts/run_experiment.py configs/multi_seed.yaml

name: multi_seed_evaluation
description: >
  Train MAPPO over 5 seeds for reliable comparison and confidence
  intervals.  Results feed into the statistical evaluation module.
tags:
  - multi-seed
  - evaluation

env:
  num_vessels: 3
  num_ports: 2
  docks_per_port: 3
  rollout_steps: 55

mappo:
  lr: 0.0003                   # Adam learning rate
  rollout_length: 50            # steps per rollout before PPO update
  num_epochs: 4                 # PPO epochs per update
  minibatch_size: 128           # samples per PPO minibatch
  clip_eps: 0.2                 # PPO clipping epsilon
  gamma: 0.99                   # discount factor
  gae_lambda: 0.95              # GAE lambda for advantage estimation
  hidden_dims: [64, 64]         # actor-critic MLP hidden layer sizes
  normalize_observations: true
  normalize_rewards: true

num_iterations: 200
num_seeds: 5                    # run over 5 seeds for statistical evaluation
seeds: [42, 49, 56, 63, 70]    # explicit seed list
eval_interval: 20
early_stopping_patience: 30     # stop if no improvement for 30 evals
checkpoint_dir: runs/multi_seed/checkpoints
output_dir: runs/multi_seed
tensorboard: false
console_log: true
log_every: 10
