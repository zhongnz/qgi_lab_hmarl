# Baseline experiment â€” standard parameters, single seed, no curriculum.
# Usage: python scripts/run_experiment.py configs/baseline.yaml

name: baseline
description: Standard MAPPO training with default hyper-parameters.
tags:
  - baseline
  - default

env:
  num_vessels: 3
  num_ports: 2
  docks_per_port: 3
  rollout_steps: 55

mappo:
  lr: 0.0003                   # Adam learning rate
  rollout_length: 50            # steps per rollout before PPO update
  num_epochs: 4                 # PPO epochs per update
  minibatch_size: 128           # samples per PPO minibatch
  clip_eps: 0.2                 # PPO clipping epsilon
  gamma: 0.99                   # discount factor
  gae_lambda: 0.95              # GAE lambda for advantage estimation
  hidden_dims: [64, 64]         # actor-critic MLP hidden layer sizes
  normalize_observations: true  # Welford running mean/std normalisation
  normalize_rewards: true       # reward scaling via running std

num_iterations: 200             # total train iterations
num_seeds: 1                    # number of seeds (1 = single run)
eval_interval: 20               # evaluate every N iterations
output_dir: runs/baseline
tensorboard: false
console_log: true
log_every: 10                   # print training stats every N iterations
