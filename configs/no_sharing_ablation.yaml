# Per-agent (no parameter sharing) ablation experiment.
# Usage: python scripts/run_experiment.py configs/no_sharing_ablation.yaml

name: no_sharing_ablation
description: >
  Alternative MAPPO training where each individual agent gets
  its own actor-critic network.  Compared against the shared-parameter
  baseline to quantify the benefit of parameter sharing in CTDE.
tags:
  - ablation
  - no-sharing
  - per-agent

env:
  num_vessels: 3
  num_ports: 2
  docks_per_port: 3
  rollout_steps: 55

mappo:
  lr: 0.0003                   # Adam learning rate
  rollout_length: 50            # steps per rollout before PPO update
  num_epochs: 4                 # PPO epochs per update
  minibatch_size: 128           # samples per PPO minibatch
  clip_eps: 0.2                 # PPO clipping epsilon
  gamma: 0.99                   # discount factor
  gae_lambda: 0.95              # GAE lambda for advantage estimation
  hidden_dims: [64, 64]         # actor-critic MLP hidden layer sizes
  normalize_observations: true
  normalize_rewards: true
  parameter_sharing: false      # each agent gets its own network (ablation)

num_iterations: 200
num_seeds: 3
seeds: [42, 49, 56]
eval_interval: 20
output_dir: runs/no_sharing
tensorboard: false
console_log: true
log_every: 10
